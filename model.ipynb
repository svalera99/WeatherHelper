{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "nlp_small = spacy.load('en_core_web_sm',disable=[\"ner\"])\n",
    "from spacy.symbols import VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embedding in google model\n",
      "No embedding in wiki model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "%run getMostSimilarTag.ipynb\n",
    "%run javaCommunicator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_res(corpus, model='english.muc.7class.distsim.crf.ser'):\n",
    "    jar = 'stnf/stanford-ner.jar'\n",
    "\n",
    "    ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "\n",
    "    words = word_tokenize(corpus)\n",
    "    return ner_tagger.tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where and when are u planing to go?\n",
      "To Lyon on 21th of July\n",
      "And what are going to do there?\n",
      "I'm going to meet friends and have a tasty burger with them\n"
     ]
    }
   ],
   "source": [
    "model = \"english.muc.7class.distsim.crf.ser\"#\"dummy-ner-model.ser.gz\"\n",
    "loc_dat = input(\"Where and when are u planing to go?\\n\")\n",
    "activity = input(\"And what are going to do there?\\n\") #\"I'm going to meet friends and have a tasty burger with them\"\n",
    "ents = show_train_res(loc_dat, model)\n",
    "ents_act = show_train_res(activity, model)\n",
    "\n",
    "loc = \" \".join([ent[0] for ent in ents if ent[1]==\"LOCATION\"])\n",
    "date = \" \".join([ent[0] for ent in ents if ent[1]==\"DATE\"])\n",
    "act = \" \".join([ent[0] for ent in ents_act if ent[1]==\"ACTIVITY\"])\n",
    "\n",
    "if not all([loc,date]):\n",
    "    pVect = returnProbabilitieVector(loc_dat, model)\n",
    "    if not loc:\n",
    "        loc = returnMostLikely(pVect, \"LOCATION\")\n",
    "    if not date:\n",
    "        date = returnMostLikely(pVect, \"DATE\")\n",
    "        \n",
    "# if not act and model != \"english.muc.7class.distsim.crf.ser\": finish when got data for ner model\n",
    "#     pVect = returnProbabilitieVector(activity, model)\n",
    "#     act = returnMostLikely(vect, \"ACTIVITY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read location is Lyon, date July, action - {'meet': ['friends'], 'have': ['burger']}\n"
     ]
    }
   ],
   "source": [
    "if not act:\n",
    "    doc = nlp_small(activity)\n",
    "    acts = {}\n",
    "    for possible_act in doc:\n",
    "        if possible_act.pos == VERB:\n",
    "            children = [child.text for child in possible_act.children if not child.is_stop and child.pos_ == \"NOUN\"]\n",
    "            if children:\n",
    "                if possible_act.text not in acts.keys():\n",
    "                    acts.update({possible_act.text: children})\n",
    "                else:\n",
    "                    acts[possible_act.text].append(children)\n",
    "\n",
    "    \n",
    "print(f\"Read location is {loc}, date {date}, action - {acts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embedding in wiki model\n",
      "No embedding in wiki model\n",
      "{'gift': 0.4827305, 'meat': 0.679823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "tag = {}\n",
    "for pos_act in acts.keys():\n",
    "    resulted_tag = getMostSimilarTag([\" \".join(acts[pos_act])])\n",
    "    most_likely_tag = max(resulted_tag.items(), key=operator.itemgetter(1))\n",
    "    tag.update({most_likely_tag[0]: most_likely_tag[1]})\n",
    "\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
